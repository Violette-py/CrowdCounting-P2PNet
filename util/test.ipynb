{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "\n",
    "def _max_by_axis_pad(the_list):\n",
    "    maxes = the_list[0]\n",
    "    for sublist in the_list[1:]:\n",
    "        for index, item in enumerate(sublist):\n",
    "            maxes[index] = max(maxes[index], item)\n",
    "\n",
    "    block = 128\n",
    "\n",
    "    for i in range(2):\n",
    "        maxes[i+1] = ((maxes[i+1] - 1) // block + 1) * block\n",
    "    return maxes\n",
    "\n",
    "\n",
    "def nested_tensor_from_tensor_list(tensor_list: List[Tensor]):\n",
    "    # TODO make this more general\n",
    "    if tensor_list[0].ndim == 3:\n",
    "\n",
    "        # TODO make it support different-sized images\n",
    "        max_size = _max_by_axis_pad([list(img.shape) for img in tensor_list])\n",
    "        # min_size = tuple(min(s) for s in zip(*[img.shape for img in tensor_list]))\n",
    "        batch_shape = [len(tensor_list)] + max_size\n",
    "        b, c, h, w = batch_shape\n",
    "        dtype = tensor_list[0].dtype\n",
    "        device = tensor_list[0].device\n",
    "        tensor = torch.zeros(batch_shape, dtype=dtype, device=device)\n",
    "        for img, pad_img in zip(tensor_list, tensor):\n",
    "            pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)\n",
    "    else:\n",
    "        raise ValueError('not supported')\n",
    "    return tensor\n",
    "\n",
    "def collate_fn_crowd(batch):\n",
    "    # re-organize the batch\n",
    "    batch_new = []\n",
    "    for b in batch:\n",
    "        imgs, points = b\n",
    "        if imgs.ndim == 3:\n",
    "            imgs = imgs.unsqueeze(0) # 将单个图像转换为形状为 [1, C, H, W] \n",
    "        # 遍历处理每个图像（如果imgs是多图像张量，则会遍历每个图像）\n",
    "        print(f\"imgs.shape = {imgs.shape}\")\n",
    "        for i in range(len(imgs)):\n",
    "            batch_new.append((imgs[i, :, :, :], points[i]))\n",
    "    print(f\"batch_new = {batch_new}\")\n",
    "    batch = batch_new\n",
    "    # print(f\"batch_new = {batch_new}\")\n",
    "    batch = list(zip(*batch))\n",
    "    print(f\"len = {len(batch)}\")\n",
    "    # print(f\"batch = {batch}\")\n",
    "    batch[0] = nested_tensor_from_tensor_list(batch[0])\n",
    "    print(f\"batch[0] = {batch[0].shape}\")\n",
    "    \n",
    "    print(f\"batch[1] = {batch[1]}\")\n",
    "    \n",
    "\n",
    "    return tuple(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points1 = [[0.6638845801353455, 0.8458588719367981], [0.4588415026664734, 0.9813203811645508], [0.3919997215270996, 0.18197685480117798], [0.047447264194488525, 0.9441867470741272], [0.8190175294876099, 0.08473968505859375]]\n",
      "points2 = [[0.8430103659629822, 0.939226508140564], [0.005113065242767334, 0.5371531248092651], [0.044196128845214844, 0.5609201192855835], [0.22545641660690308, 0.8165781497955322], [0.019254744052886963, 0.25466984510421753]]\n",
      "imgs.shape = torch.Size([1, 3, 100, 200])\n",
      "imgs.shape = torch.Size([1, 3, 150, 250])\n",
      "batch_new = [(tensor([[[0.0143, 0.2860, 0.4216,  ..., 0.6058, 0.7872, 0.6927],\n",
      "         [0.3401, 0.9436, 0.9291,  ..., 0.8825, 0.4819, 0.6070],\n",
      "         [0.2620, 0.0966, 0.5824,  ..., 0.6841, 0.3647, 0.4097],\n",
      "         ...,\n",
      "         [0.8482, 0.7748, 0.1538,  ..., 0.5402, 0.0044, 0.3309],\n",
      "         [0.3356, 0.7458, 0.9334,  ..., 0.2713, 0.4069, 0.0588],\n",
      "         [0.0311, 0.8886, 0.8130,  ..., 0.3560, 0.3384, 0.7228]],\n",
      "\n",
      "        [[0.9368, 0.9747, 0.5108,  ..., 0.5972, 0.7276, 0.3201],\n",
      "         [0.0829, 0.8822, 0.6988,  ..., 0.3734, 0.3554, 0.5502],\n",
      "         [0.7675, 0.9616, 0.6443,  ..., 0.9501, 0.8898, 0.4629],\n",
      "         ...,\n",
      "         [0.4784, 0.7919, 0.9018,  ..., 0.3299, 0.2454, 0.0825],\n",
      "         [0.6281, 0.4759, 0.5095,  ..., 0.8169, 0.8963, 0.6123],\n",
      "         [0.2572, 0.7066, 0.7376,  ..., 0.0566, 0.6800, 0.9907]],\n",
      "\n",
      "        [[0.7610, 0.5100, 0.1037,  ..., 0.1341, 0.1868, 0.9298],\n",
      "         [0.1535, 0.1112, 0.6222,  ..., 0.9452, 0.4147, 0.7815],\n",
      "         [0.3490, 0.8700, 0.3546,  ..., 0.4659, 0.6127, 0.9107],\n",
      "         ...,\n",
      "         [0.8882, 0.7220, 0.4250,  ..., 0.0890, 0.1805, 0.2707],\n",
      "         [0.8610, 0.8075, 0.6476,  ..., 0.0462, 0.7120, 0.3657],\n",
      "         [0.0512, 0.7551, 0.3459,  ..., 0.3699, 0.0785, 0.3171]]]), [0.6638845801353455, 0.8458588719367981]), (tensor([[[0.9018, 0.0783, 0.3297,  ..., 0.8827, 0.3260, 0.5334],\n",
      "         [0.2462, 0.0643, 0.8169,  ..., 0.6763, 0.5626, 0.3599],\n",
      "         [0.8884, 0.7892, 0.0449,  ..., 0.6852, 0.7524, 0.2790],\n",
      "         ...,\n",
      "         [0.7304, 0.8908, 0.7795,  ..., 0.2752, 0.6568, 0.4009],\n",
      "         [0.0451, 0.5123, 0.5017,  ..., 0.8965, 0.9883, 0.8505],\n",
      "         [0.8065, 0.9772, 0.0358,  ..., 0.2593, 0.5109, 0.8267]],\n",
      "\n",
      "        [[0.4062, 0.6711, 0.9823,  ..., 0.3877, 0.0838, 0.3253],\n",
      "         [0.8908, 0.0451, 0.7560,  ..., 0.7367, 0.1596, 0.2428],\n",
      "         [0.5003, 0.8501, 0.3595,  ..., 0.8535, 0.5467, 0.0765],\n",
      "         ...,\n",
      "         [0.5548, 0.9769, 0.7822,  ..., 0.8376, 0.7902, 0.4346],\n",
      "         [0.3030, 0.5759, 0.8938,  ..., 0.1931, 0.5701, 0.0128],\n",
      "         [0.3361, 0.6240, 0.4157,  ..., 0.9268, 0.3681, 0.3183]],\n",
      "\n",
      "        [[0.1043, 0.4950, 0.5308,  ..., 0.1646, 0.7249, 0.5595],\n",
      "         [0.4008, 0.9928, 0.2998,  ..., 0.0214, 0.2569, 0.4908],\n",
      "         [0.4827, 0.9432, 0.7041,  ..., 0.4615, 0.2726, 0.3000],\n",
      "         ...,\n",
      "         [0.4998, 0.2938, 0.2831,  ..., 0.0163, 0.4329, 0.4803],\n",
      "         [0.6580, 0.9945, 0.4960,  ..., 0.3533, 0.5923, 0.6501],\n",
      "         [0.8842, 0.9379, 0.5090,  ..., 0.9193, 0.3436, 0.9287]]]), [0.8430103659629822, 0.939226508140564])]\n",
      "len = 2\n",
      "batch[0] = torch.Size([2, 3, 256, 256])\n",
      "batch[1] = ([0.6638845801353455, 0.8458588719367981], [0.8430103659629822, 0.939226508140564])\n",
      "result = ([0.6638845801353455, 0.8458588719367981], [0.8430103659629822, 0.939226508140564])\n"
     ]
    }
   ],
   "source": [
    "# 假设图像的高度和宽度\n",
    "c1, height1, width1 = 3, 100, 200\n",
    "c2, height2, width2 = 3, 150, 250\n",
    "\n",
    "# 创建两个随机图像张量\n",
    "img1 = torch.rand(c1, height1, width1)\n",
    "img2 = torch.rand(c2, height2, width2)\n",
    "\n",
    "# 创建对应的随机标注点\n",
    "# 假设每个图像有5个标注点\n",
    "points1 = torch.rand(5, 2).tolist()\n",
    "points2 = torch.rand(5, 2).tolist()\n",
    "\n",
    "print(f\"points1 = {points1}\")\n",
    "print(f\"points2 = {points2}\")\n",
    "\n",
    "# 创建批次数据\n",
    "batch = [\n",
    "    (img1, points1),  # img1: [c1, H1, W1], points1: [N1, 2]\n",
    "    (img2, points2)   # img2: [c2, H2, W2], points2: [N2, 2]\n",
    "]\n",
    "\n",
    "result = collate_fn_crowd(batch)\n",
    "print(f\"result = {result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, [], [], []]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[]]*4\n",
    "a[0] = 1\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
